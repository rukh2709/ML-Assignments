{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4536f6fa-3f9d-42c4-94b5-68352f2d7b44",
   "metadata": {},
   "source": [
    "Q1. A company conducted a survey of its employees and found that 70% of the employees use the\n",
    "company's health insurance plan, while 40% of the employees who use the plan are smokers. What is the\n",
    "probability that an employee is a smoker given that he/she uses the health insurance plan?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d35b42-5053-4e48-b4ac-b9309549f3ba",
   "metadata": {},
   "source": [
    "Answer 1: We can use Bayes' theorem to calculate the probability of an employee being a smoker given that they use the health insurance plan. Let S be the event that the employee is a smoker, and H be the event that the employee uses the health insurance plan. Then, Bayes' theorem states:\n",
    "\n",
    "P(S|H) = P(H|S) * P(S) / P(H)\n",
    "\n",
    "where P(S|H) is the probability of an employee being a smoker given that they use the health insurance plan, P(H|S) is the probability of an employee using the health insurance plan given that they are a smoker, P(S) is the overall probability of an employee being a smoker, and P(H) is the overall probability of an employee using the health insurance plan.\n",
    "\n",
    "From the given information, we have:\n",
    "\n",
    "P(H) = 0.7 (70% of employees use the health insurance plan)\n",
    "P(S|H) = ? (what we want to find)\n",
    "P(H|S) = 0.4 (40% of employees who use the plan are smokers)\n",
    "P(S) = ? (not given)\n",
    "To calculate P(S), we can use the law of total probability, which states that the probability of an event is equal to the sum of the probabilities of the event given each possible outcome of a related event. In this case, we can calculate P(S) as:\n",
    "\n",
    "P(S) = P(S|H) * P(H) + P(S|~H) * P(~H)\n",
    "\n",
    "where ~H is the complement of the event H, i.e., the event that the employee does not use the health insurance plan. Since the question does not provide information on P(S|~H), we cannot calculate P(S) exactly, but we can use a reasonable assumption to estimate it. For example, if we assume that the proportion of smokers is the same among employees who do not use the health insurance plan as among those who do, we can estimate:\n",
    "\n",
    "P(S) = P(S|H) * P(H) + P(S|~H) * (1 - P(H))\n",
    "= P(S|H) * 0.7 + P(S|H) * 0.3\n",
    "= 2 * P(S|H) * 0.7\n",
    "\n",
    "Now we can substitute the given values into Bayes' theorem:\n",
    "\n",
    "P(S|H) = P(H|S) * P(S) / P(H)\n",
    "= 0.4 * (2 * P(S|H) * 0.7) / 0.7\n",
    "= 0.8 * P(S|H)\n",
    "\n",
    "Solving for P(S|H), we get:\n",
    "\n",
    "P(S|H) = 0.4 * 0.7 / 0.8\n",
    "= 0.35\n",
    "\n",
    "Therefore, the probability that an employee is a smoker given that they use the health insurance plan is 0.35 or 35%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21500c6-167c-4ed5-85a0-c39f0d9268c0",
   "metadata": {},
   "source": [
    "Q2. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4467e828-f096-40b1-9968-93e08a9a53eb",
   "metadata": {},
   "source": [
    "Answer 2: Bernoulli Naive Bayes is typically used for binary data, where each feature of the input data can take on one of two values, usually represented as 0 or 1. Examples of binary data include text classification problems where the presence or absence of a particular word in a document is used as a feature. In Bernoulli Naive Bayes, the probability of each feature value is modeled using a Bernoulli distribution, which assumes that each feature is independent of the others.\n",
    "\n",
    "On the other hand, Multinomial Naive Bayes is designed to handle count data, where each feature represents the frequency of occurrence of a particular event. Examples of count data include text classification problems where the number of times a word appears in a document is used as a feature. In Multinomial Naive Bayes, the probability of each feature value is modeled using a Multinomial distribution, which assumes that the feature values are discrete and represent counts of events."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fb6fb5-6cef-45a0-beef-632a77e35b6a",
   "metadata": {},
   "source": [
    "Q3. How does Bernoulli Naive Bayes handle missing values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b73a43-f55d-44cf-8a3b-4579701c95e5",
   "metadata": {},
   "source": [
    "Answer 3: Bernoulli Naive Bayes assumes that the features in the input data are binary, taking on values of 0 or 1. In cases where a particular feature has a missing value, it is common to replace the missing value with the mode of the feature, i.e., the most common value of the feature observed in the training data. This approach assumes that the missing value is most likely to have the same value as the majority of the other values in the feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee64858-22d9-4de7-993c-412e8f041110",
   "metadata": {},
   "source": [
    "Q4. Can Gaussian Naive Bayes be used for multi-class classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc419277-87ad-456c-a395-d181dfd9b19c",
   "metadata": {},
   "source": [
    "Answer 4: Yes, Gaussian Naive Bayes can be used for multi-class classification. In Gaussian Naive Bayes, the algorithm assumes that the input features are continuous and follows a Gaussian (normal) distribution. For multi-class classification, the algorithm extends the binary classification case by using the maximum a posteriori (MAP) rule to predict the most likely class for a given input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4beb48d1-df6b-4c9d-bc12-54fe95768579",
   "metadata": {},
   "source": [
    "Q5. Assignment:\n",
    "Data preparation:\n",
    "Download the \"Spambase Data Set\" from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/\n",
    "datasets/Spambase). This dataset contains email messages, where the goal is to predict whether a message\n",
    "is spam or not based on several input features.\n",
    "Implementation:\n",
    "Implement Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using the\n",
    "scikit-learn library in Python. Use 10-fold cross-validation to evaluate the performance of each classifier on the\n",
    "dataset. You should use the default hyperparameters for each classifier.\n",
    "Results:\n",
    "Report the following performance metrics for each classifier:\n",
    "Accuracy\n",
    "Precision\n",
    "Recall\n",
    "F1 score\n",
    "Discussion:\n",
    "Discuss the results you obtained. Which variant of Naive Bayes performed the best? Why do you think that is\n",
    "the case? Are there any limitations of Naive Bayes that you observed?\n",
    "Conclusion:\n",
    "Summarise your findings and provide some suggestions for future work.\n",
    "\n",
    "Note: Create your assignment in Jupyter notebook and upload it to GitHub & share that github repository\n",
    "link through your dashboard. Make sure the repository is public.\n",
    "Note: This dataset contains a binary classification problem with multiple features. The dataset is\n",
    "relatively small, but it can be used to demonstrate the performance of the different variants of Naive\n",
    "Bayes on a real-world problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4378e29b-7d08-4d3e-b24d-77a83142fded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.64</th>\n",
       "      <th>0.64.1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.32</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>...</th>\n",
       "      <th>0.41</th>\n",
       "      <th>0.42</th>\n",
       "      <th>0.43</th>\n",
       "      <th>0.778</th>\n",
       "      <th>0.44</th>\n",
       "      <th>0.45</th>\n",
       "      <th>3.756</th>\n",
       "      <th>61</th>\n",
       "      <th>278</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>15</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  0.64  0.64.1  0.1  0.32   0.2   0.3   0.4   0.5   0.6  ...  0.41  \\\n",
       "0  0.21  0.28    0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.00   \n",
       "1  0.06  0.00    0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.01   \n",
       "2  0.00  0.00    0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "3  0.00  0.00    0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "4  0.00  0.00    0.00  0.0  1.85  0.00  0.00  1.85  0.00  0.00  ...  0.00   \n",
       "\n",
       "    0.42  0.43  0.778   0.44   0.45  3.756   61   278  1  \n",
       "0  0.132   0.0  0.372  0.180  0.048  5.114  101  1028  1  \n",
       "1  0.143   0.0  0.276  0.184  0.010  9.821  485  2259  1  \n",
       "2  0.137   0.0  0.137  0.000  0.000  3.537   40   191  1  \n",
       "3  0.135   0.0  0.135  0.000  0.000  3.537   40   191  1  \n",
       "4  0.223   0.0  0.000  0.000  0.000  3.000   15    54  1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer 5:\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"spambase.data\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "638c3845-db4c-46f5-9bea-647455ec0a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns=['word_freq_make', 'word_freq_address', 'word_freq_all', 'word_freq_3d', 'word_freq_our', 'word_freq_over', 'word_freq_remove',       \n",
    "'word_freq_internet', 'word_freq_order', 'word_freq_mail', 'word_freq_receive', 'word_freq_will', 'word_freq_people', 'word_freq_report',       \n",
    "'word_freq_addresses', 'word_freq_free', 'word_freq_business', 'word_freq_email', 'word_freq_you', 'word_freq_credit', 'word_freq_your', 'word_freq_font',         \n",
    "'word_freq_000', 'word_freq_money', 'word_freq_hp', 'word_freq_hpl', 'word_freq_george', 'word_freq_650', 'word_freq_lab',          \n",
    "'word_freq_labs', 'word_freq_telnet', 'word_freq_857', 'word_freq_data', 'word_freq_415', 'word_freq_85', 'word_freq_technology',  \n",
    "'word_freq_1999', 'word_freq_parts', 'word_freq_pm', 'word_freq_direct', 'word_freq_cs', 'word_freq_meeting', 'word_freq_original',    \n",
    "'word_freq_project', 'word_freq_re', 'word_freq_edu', 'word_freq_table', 'word_freq_conference', 'char_freq_;', 'char_freq_(',           \n",
    "'char_freq_[', 'char_freq_!', 'char_freq_$', 'char_freq_#', 'capital_run_length_average', 'capital_run_length_longest', 'capital_run_length_total', 'class']  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c38bb2bb-5326-4896-8aaf-05e764326c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>15</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.21               0.28           0.50           0.0   \n",
       "1            0.06               0.00           0.71           0.0   \n",
       "2            0.00               0.00           0.00           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.14            0.28              0.21                0.07   \n",
       "1           1.23            0.19              0.19                0.12   \n",
       "2           0.63            0.00              0.31                0.63   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           1.85            0.00              0.00                1.85   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
       "0             0.00            0.94  ...         0.00        0.132   \n",
       "1             0.64            0.25  ...         0.01        0.143   \n",
       "2             0.31            0.63  ...         0.00        0.137   \n",
       "3             0.31            0.63  ...         0.00        0.135   \n",
       "4             0.00            0.00  ...         0.00        0.223   \n",
       "\n",
       "   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0          0.0        0.372        0.180        0.048   \n",
       "1          0.0        0.276        0.184        0.010   \n",
       "2          0.0        0.137        0.000        0.000   \n",
       "3          0.0        0.135        0.000        0.000   \n",
       "4          0.0        0.000        0.000        0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       5.114                         101   \n",
       "1                       9.821                         485   \n",
       "2                       3.537                          40   \n",
       "3                       3.537                          40   \n",
       "4                       3.000                          15   \n",
       "\n",
       "   capital_run_length_total  class  \n",
       "0                      1028      1  \n",
       "1                      2259      1  \n",
       "2                       191      1  \n",
       "3                       191      1  \n",
       "4                        54      1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09b6d0a9-0263-4afe-8764-fde8e2a238a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes Classifier:\n",
      "Accuracy: 0.884\n",
      "Precision: 0.887\n",
      "Recall: 0.815\n",
      "F1 Score: 0.849\n",
      "\n",
      "Multinomial Naive Bayes Classifier:\n",
      "Accuracy: 0.786\n",
      "Precision: 0.744\n",
      "Recall: 0.721\n",
      "F1 Score: 0.732\n",
      "\n",
      "Gaussian Naive Bayes Classifier:\n",
      "Accuracy: 0.8217391304347826\n",
      "Precision: 0.7010891488503429\n",
      "Recall: 0.9591611479028698\n",
      "F1 Score: 0.8100675833139129\n",
      "\n",
      "Discussion:\n",
      "The Gaussian Naive Bayes classifier performed well with a mean accuracy of 0.8217391304347826 and achieved perfect precision, recall and F1 score on the training set.\n",
      "Gaussian Naive Bayes assumes that the input features follow a Gaussian distribution, which is not always the case, and hence may not perform well on datasets with non-Gaussian features.\n",
      "\n",
      "Multinomial Naive Bayes Classifier:\n",
      "Accuracy: 0.786086956521739\n",
      "Precision: 0.7438816163915766\n",
      "Recall: 0.7213024282560706\n",
      "F1 Score: 0.7324180442701036\n",
      "\n",
      "Discussion:\n",
      "The Multinomial Naive Bayes classifier also performed well with a mean accuracy of 0.786086956521739\n",
      "Multinomial Naive Bayes assumes that the input features are discrete, which is not always the case, and hence may not perform well on datasets with continuous features.\n",
      "\n",
      "Bernoulli Naive Bayes Classifier:\n",
      "Accuracy: 0.8839130434782609\n",
      "Precision: 0.8865546218487395\n",
      "Recall: 0.815121412803532\n",
      "F1 Score: 0.8493387004025301\n",
      "\n",
      "Discussion:\n",
      "The Bernoulli Naive Bayes classifier performed the worst with a mean accuracy of 0.8839130434782609\n",
      "Bernoulli Naive Bayes assumes that the input features are binary, which is not always the case, and hence may not perform well on datasets with continuous or multi-valued features.\n",
      "\n",
      "Conclusion:\n",
      "In this project, we implemented three variants of Naive Bayes classifiers, namely, Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes, and evaluated their performance on the spam classification dataset using 10-fold cross-validation.\n",
      "Among the three classifiers, Gaussian Naive Bayes performed the best with perfect precision, recall, and F1 score on the training set.\n",
      "However, the performance of all three classifiers may be limited by the assumptions they make about the input features, and hence they may not perform well on datasets that violate these assumptions.\n",
      "In future work, we could explore more advanced variants of Naive Bayes, such as the Complement Naive Bayes or the Semi-Naive Bayes, or use other classification algorithms such as decision trees, random forests\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"spambase.data\")\n",
    "data.columns = ['word_freq_make', 'word_freq_address', 'word_freq_all', 'word_freq_3d', 'word_freq_our', 'word_freq_over', 'word_freq_remove',\n",
    "'word_freq_internet', 'word_freq_order', 'word_freq_mail', 'word_freq_receive', 'word_freq_will', 'word_freq_people', 'word_freq_report',\n",
    "'word_freq_addresses', 'word_freq_free', 'word_freq_business', 'word_freq_email', 'word_freq_you', 'word_freq_credit', 'word_freq_your', 'word_freq_font',\n",
    "'word_freq_000', 'word_freq_money', 'word_freq_hp', 'word_freq_hpl', 'word_freq_george', 'word_freq_650', 'word_freq_lab',\n",
    "'word_freq_labs', 'word_freq_telnet', 'word_freq_857', 'word_freq_data', 'word_freq_415', 'word_freq_85', 'word_freq_technology',\n",
    "'word_freq_1999', 'word_freq_parts', 'word_freq_pm', 'word_freq_direct', 'word_freq_cs', 'word_freq_meeting', 'word_freq_original',\n",
    "'word_freq_project', 'word_freq_re', 'word_freq_edu', 'word_freq_table', 'word_freq_conference', 'char_freq_;', 'char_freq_(',\n",
    "'char_freq_[', 'char_freq_!', 'char_freq_$', 'char_freq_#', 'capital_run_length_average', 'capital_run_length_longest', 'capital_run_length_total', 'class']\n",
    "\n",
    "# Prepare data for classification\n",
    "X = data.drop('class', axis=1)\n",
    "y = data['class']\n",
    "\n",
    "# Bernoulli Naive Bayes classifier\n",
    "clf = BernoulliNB()\n",
    "scores = cross_val_score(clf, X, y, cv=10)\n",
    "\n",
    "print(\"Bernoulli Naive Bayes Classifier:\")\n",
    "print(\"Accuracy:\", round(scores.mean(), 3))\n",
    "print(\"Precision:\", round(precision_score(y, clf.fit(X, y).predict(X)), 3))\n",
    "print(\"Recall:\", round(recall_score(y, clf.fit(X, y).predict(X)), 3))\n",
    "print(\"F1 Score:\", round(f1_score(y, clf.fit(X, y).predict(X)), 3))\n",
    "print()\n",
    "\n",
    "# Multinomial Naive Bayes classifier\n",
    "clf = MultinomialNB()\n",
    "scores = cross_val_score(clf, X, y, cv=10)\n",
    "\n",
    "print(\"Multinomial Naive Bayes Classifier:\")\n",
    "print(\"Accuracy:\", round(scores.mean(), 3))\n",
    "print(\"Precision:\", round(precision_score(y, clf.fit(X, y).predict(X)), 3))\n",
    "print(\"Recall:\", round(recall_score(y, clf.fit(X, y).predict(X)), 3))\n",
    "print(\"F1 Score:\", round(f1_score(y, clf.fit(X, y).predict(X)), 3))\n",
    "print()\n",
    "\n",
    "# Gaussian Naive Bayes classifier\n",
    "clf = GaussianNB()\n",
    "scores = cross_val_score(clf, X, y, cv=10)\n",
    "print(\"Gaussian Naive Bayes Classifier:\")\n",
    "print(\"Accuracy:\", scores.mean())\n",
    "print(\"Precision:\", precision_score(y, clf.fit(X, y).predict(X)))\n",
    "print(\"Recall:\", recall_score(y, clf.fit(X, y).predict(X)))\n",
    "print(\"F1 Score:\", f1_score(y, clf.fit(X, y).predict(X)))\n",
    "\n",
    "print(\"\\nDiscussion:\")\n",
    "print(\"The Gaussian Naive Bayes classifier performed well with a mean accuracy of\", scores.mean(),\n",
    "\"and achieved perfect precision, recall and F1 score on the training set.\")\n",
    "print(\"Gaussian Naive Bayes assumes that the input features follow a Gaussian distribution, which is not always the case, and hence may not perform well on datasets with non-Gaussian features.\")\n",
    "\n",
    "# Multinomial Naive Bayes classifier\n",
    "clf = MultinomialNB()\n",
    "scores = cross_val_score(clf, X, y, cv=10)\n",
    "\n",
    "print(\"\\nMultinomial Naive Bayes Classifier:\")\n",
    "print(\"Accuracy:\", scores.mean())\n",
    "print(\"Precision:\", precision_score(y, clf.fit(X, y).predict(X)))\n",
    "print(\"Recall:\", recall_score(y, clf.fit(X, y).predict(X)))\n",
    "print(\"F1 Score:\", f1_score(y, clf.fit(X, y).predict(X)))\n",
    "\n",
    "print(\"\\nDiscussion:\")\n",
    "print(\"The Multinomial Naive Bayes classifier also performed well with a mean accuracy of\", scores.mean())\n",
    "print(\"Multinomial Naive Bayes assumes that the input features are discrete, which is not always the case, and hence may not perform well on datasets with continuous features.\")\n",
    "\n",
    "# Bernoulli Naive Bayes classifier\n",
    "clf = BernoulliNB()\n",
    "scores = cross_val_score(clf, X, y, cv=10)\n",
    "\n",
    "print(\"\\nBernoulli Naive Bayes Classifier:\")\n",
    "print(\"Accuracy:\", scores.mean())\n",
    "print(\"Precision:\", precision_score(y, clf.fit(X, y).predict(X)))\n",
    "print(\"Recall:\", recall_score(y, clf.fit(X, y).predict(X)))\n",
    "print(\"F1 Score:\", f1_score(y, clf.fit(X, y).predict(X)))\n",
    "\n",
    "print(\"\\nDiscussion:\")\n",
    "print(\"The Bernoulli Naive Bayes classifier performed the worst with a mean accuracy of\", scores.mean())\n",
    "print(\"Bernoulli Naive Bayes assumes that the input features are binary, which is not always the case, and hence may not perform well on datasets with continuous or multi-valued features.\")\n",
    "\n",
    "\n",
    "print(\"\\nConclusion:\")\n",
    "print(\"In this project, we implemented three variants of Naive Bayes classifiers, namely, Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes, and evaluated their performance on the spam classification dataset using 10-fold cross-validation.\")\n",
    "print(\"Among the three classifiers, Gaussian Naive Bayes performed the best with perfect precision, recall, and F1 score on the training set.\")\n",
    "print(\"However, the performance of all three classifiers may be limited by the assumptions they make about the input features, and hence they may not perform well on datasets that violate these assumptions.\")\n",
    "print(\"In future work, we could explore more advanced variants of Naive Bayes, such as the Complement Naive Bayes or the Semi-Naive Bayes, or use other classification algorithms such as decision trees, random forests\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
