{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34688028-da97-4a9f-95f1-600c2725ebfb",
   "metadata": {},
   "source": [
    "Q1. You are working on a machine learning project where you have a dataset containing numerical and\n",
    "categorical features. You have identified that some of the features are highly correlated and there are\n",
    "missing values in some of the columns. You want to build a pipeline that automates the feature\n",
    "engineering process and handles the missing values\n",
    "Design a pipeline that includes the following steps:\n",
    "Use an automated feature selection method to identify the important features in the dataset.\n",
    "Create a numerical pipeline that includes the following steps.\n",
    "Impute the missing values in the numer#cal columns using the mean of the column values.\n",
    "Scale the numerical columns using standardisation.\n",
    "Create a categorical pipeline that includes the following steps.\n",
    "Impute the missing values in the categorical columns using the most frequent value of the column.\n",
    "One-hot encode the categorical columns.\n",
    "Combine the numerical and categorical ppelines using a Column Transformer.\n",
    "Use a Random Forest Classifier to build the final model.\n",
    "Evaluate the accuracy of the model on the test dataset.\n",
    "Note! Your solution should include code snippets for each step of the pipeline, and a brief explanation of\n",
    "each step. You should also provide an interpretation of the results and suggest possible improvements for\n",
    "the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3f8894-5a5f-41ca-ac10-c89933022b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answerr 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c958b93f-5a7d-46a9-b7be-677d0959ed8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9591836734693877\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "\n",
    "# Load iris dataset\n",
    "df=sns.load_dataset('tips')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder=LabelEncoder()\n",
    "df['time']=encoder.fit_transform(df.time)\n",
    "\n",
    "## independent and dependent feature\n",
    "X=df.drop(labels=['time'],axis=1)\n",
    "y=df.time\n",
    "\n",
    "\n",
    "# Import the dataset and split it into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "categorical_cols = ['sex', 'smoker','day']\n",
    "numerical_cols = ['total_bill', 'tip','size']\n",
    "\n",
    "# Define the numerical pipeline\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Define the categorical pipeline\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine the numerical and categorical pipelines using ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numerical_pipeline, numerical_cols),\n",
    "    ('cat', categorical_pipeline, categorical_cols)\n",
    "])\n",
    "\n",
    "# Use SelectKBest with f_classif to automatically select important features\n",
    "feature_selector = SelectKBest(f_classif, k=10)\n",
    "\n",
    "# Combine the preprocessor and feature selector with a Random Forest Classifier\n",
    "clf = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selector', feature_selector),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Fit the model on the training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the accuracy of the model on the test set\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f3e0de-27c1-4db3-8471-b9d2a53069e0",
   "metadata": {},
   "source": [
    "Q2. Build a pipeline that includes a random forest classifier and a logistic regression classifier, and then\n",
    "use a voting classifier to combine their predictions. Train the pipeline on the iris dataset and evaluate its accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9824ef13-9956-44bb-8db8-d14b54328cae",
   "metadata": {},
   "source": [
    "Answer 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e0d8518-e055-4abe-b57a-24aeb43a96de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the voting classifier: 100.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create pipelines for random forest and logistic regression classifiers\n",
    "rf_pipeline = Pipeline([('scaler', StandardScaler()), ('rf', RandomForestClassifier(random_state=42))])\n",
    "lr_pipeline = Pipeline([('scaler', StandardScaler()), ('lr', LogisticRegression(random_state=42))])\n",
    "\n",
    "# Create a voting classifier by combining the pipelines\n",
    "voting_clf = VotingClassifier(estimators=[('rf', rf_pipeline), ('lr', lr_pipeline)], voting='hard')\n",
    "\n",
    "# Train the voting classifier on the training data\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the accuracy of the voting classifier on the testing data\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of the voting classifier: {:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd91e0ce-ff6a-47cc-8a00-7e6a843f8291",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
