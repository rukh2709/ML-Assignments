{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fca7fdc-4278-490b-8c2e-31c9af8629e9",
   "metadata": {},
   "source": [
    "Q1. What is anomaly detection and what is its purpose?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b15829a-ca5c-4867-92c2-7db03648a51d",
   "metadata": {},
   "source": [
    "Answer 1: Anomaly detection is the process of identifying patterns or data points that deviate significantly from the expected or normal behavior of a system. The purpose of anomaly detection is to identify and flag observations or events that are unusual or rare, and may indicate potential problems, errors, fraud, or anomalies in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7760a1d0-4942-4dd8-990e-025fe4f9e2a9",
   "metadata": {},
   "source": [
    "Q2. What are the key challenges in anomaly detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a906d2-888b-4eab-8094-a40ad5e6e984",
   "metadata": {},
   "source": [
    "Answer 2: \n",
    "\n",
    "1. Lack of labeled data: Anomaly detection often requires large amounts of labeled data to train models and algorithms. However, labeled data can be difficult and expensive to obtain, especially for rare and unusual events.\n",
    "\n",
    "2. High dimensionality: Many real-world datasets have a high number of dimensions, which can make it difficult to identify meaningful patterns and anomalies. Dimensionality reduction techniques and feature selection can help to address this challenge.\n",
    "\n",
    "3. Imbalanced datasets: Anomaly detection often deals with imbalanced datasets where normal data vastly outnumber anomalous data. This can lead to poor performance of the detection algorithm for rare anomalies.\n",
    "\n",
    "4. Concept drift: The distribution of the data may change over time, making it difficult to develop a robust model that can adapt to changes in the data distribution.\n",
    "\n",
    "5. Lack of interpretability: Some anomaly detection algorithms may be complex and difficult to interpret, making it difficult to understand the reasons for detecting an anomaly.\n",
    "\n",
    "6. False positives and false negatives: Anomaly detection algorithms can produce false positives, identifying normal data as anomalies, or false negatives, failing to identify actual anomalies.\n",
    "\n",
    "7. Scalability: Anomaly detection algorithms should be able to handle large datasets efficiently and effectively.\n",
    "\n",
    "8. Domain-specific knowledge: In many cases, domain-specific knowledge and expertise are needed to understand the context and significance of the detected anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ade42c-5ac4-4ae1-9b8a-7754af4a7d30",
   "metadata": {},
   "source": [
    "Q3. How does unsupervised anomaly detection differ from supervised anomaly detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7486319f-a71b-41cd-ae3a-0004c04f2d64",
   "metadata": {},
   "source": [
    "Answer 3: The main differences between unsupervised and supervised anomaly detection are:\n",
    "\n",
    "1. Availability of labeled data: Unsupervised methods do not require labeled data, while supervised methods rely on labeled data for training.\n",
    "\n",
    "2. Flexibility: Unsupervised methods are more flexible and can adapt to different types of anomalies and data distributions, while supervised methods may be limited by the quality and quantity of labeled data.\n",
    "\n",
    "3. Interpretability: Unsupervised methods may be less interpretable than supervised methods, as they rely on modeling the normal behavior of the system without explicit labels.\n",
    "\n",
    "4. Performance: Supervised methods can achieve higher accuracy in detecting anomalies when trained on high-quality labeled data, while unsupervised methods may have higher false positive rates due to the lack of labeled data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58ac1b8-b090-48b8-83f6-d93cc6c7b142",
   "metadata": {},
   "source": [
    "Q4. What are the main categories of anomaly detection algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b103d243-b913-4c63-84c9-de7cea19bee3",
   "metadata": {},
   "source": [
    "Answer 4: There are several categories of anomaly detection algorithms, including:\n",
    "\n",
    "1. Statistical Methods: These methods involve modeling the normal behavior of the data using statistical techniques such as Gaussian distribution, clustering, or density estimation. The anomalies are identified as observations that deviate significantly from the expected normal behavior.\n",
    "\n",
    "2. Machine Learning Methods: These methods involve training a model on labeled data, where anomalies are identified and labeled by domain experts. The trained model is then used to identify anomalies in new, unseen data.\n",
    "\n",
    "3. Information Theoretic Methods: These methods involve measuring the amount of information required to represent the data, and identifying observations that require significantly more or less information than the expected normal behavior.\n",
    "\n",
    "4. Spectral Methods: These methods involve modeling the data as a graph or network, and identifying anomalies based on their distance or connectivity in the graph.\n",
    "\n",
    "5. Proximity-Based Methods: These methods involve measuring the similarity or dissimilarity between observations, and identifying anomalies based on their distance or proximity to other observations.\n",
    "\n",
    "6. Domain-Specific Methods: These methods involve using domain-specific knowledge or expertise to identify anomalies. For example, in network intrusion detection, anomalies may be identified based on unusual network traffic patterns or suspicious activity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06029bda-685f-4f31-b5fb-cda17879e55f",
   "metadata": {},
   "source": [
    "Q5. What are the main assumptions made by distance-based anomaly detection methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b9d6ae-7445-4913-a0b5-60e7bba11632",
   "metadata": {},
   "source": [
    "Answer 5: Distance-based anomaly detection methods methods assume that:\n",
    "\n",
    "1. Normal data points are distributed uniformly across the feature space, while anomalies are sparse and located far away from the normal data clusters.\n",
    "2. Anomalies can be identified based on their distance or proximity to other data points.\n",
    "3. The density of the normal data points is higher than the density of the anomalies.\n",
    "4. The distance metric used to measure the similarity between data points is appropriate for the data and the application.\n",
    "5. The data is represented in a low-dimensional space where the distance metric is meaningful and useful for detecting anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43499e27-5f74-4a97-8b16-2b446df7ceff",
   "metadata": {},
   "source": [
    "Q6. How does the LOF algorithm compute anomaly scores?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9c49e4-1f56-48fe-87c4-03355819c9c1",
   "metadata": {},
   "source": [
    "Answer 6: The Local Outlier Factor (LOF) algorithm computes anomaly scores for each data point by comparing its local density to the local densities of its neighboring data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173398f6-19c5-4adb-8c13-b2d0e02f3045",
   "metadata": {},
   "source": [
    "Q7. What are the key parameters of the Isolation Forest algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fca896b-50da-4fd4-9f31-94af69e3722b",
   "metadata": {},
   "source": [
    "Answer 7: The Isolation Forest algorithm has two key parameters: the number of trees (n_estimators) and the maximum depth of each tree (max_depth)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d362e441-4155-49a8-ad06-8b00be304bc2",
   "metadata": {},
   "source": [
    "Q8. If a data point has only 2 neighbours of the same class within a radius of 0.5, what is its anomaly score\n",
    "using KNN with K=10?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2704161a-894e-4c9b-92e9-db44d2b7fbc1",
   "metadata": {},
   "source": [
    "Answer 8: To calculate the anomaly score of a data point using K-nearest neighbors (KNN) with K=10, we need to determine the proportion of its neighbors that belong to a different class. In this case, since the data point has only 2 neighbors within a radius of 0.5, we consider those 2 neighbors.\n",
    "\n",
    "If both of the data point's neighbors belong to the same class, the anomaly score would be 0 because there are no neighbors of a different class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98fa639-2e3f-486a-a162-edcefdd6ee9c",
   "metadata": {},
   "source": [
    "Q9. Using the Isolation Forest algorithm with 100 trees and a dataset of 3000 data points, what is the\n",
    "anomaly score for a data point that has an average path length of 5.0 compared to the average path\n",
    "length of the trees?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e119c25-b178-4d4f-9710-7a0f162a2469",
   "metadata": {},
   "source": [
    "Answer 9: we have a dataset of 3000 data points and a forest of 100 isolation trees. Let's assume that the average path length of the data points in the trees is 10.0. If a particular data point has an average path length of 5.0, it means that it requires fewer splits to isolate it from the rest of the data, and is therefore more likely to be an anomaly.\n",
    "\n",
    "To compute the anomaly score of this data point, we can normalize its average path length by dividing it by the expected average path length of an isolated data point in the forest. This expected value is given by:\n",
    "\n",
    "E(h(x)) = c(n) + 2 * H(n-1) / (n-1)\n",
    "\n",
    "where n is the number of data points in the dataset, c(n) is a constant that depends on n, and H(n-1) is the nth harmonic number. For n = 3000, we can approximate E(h(x)) as:\n",
    "\n",
    "E(h(x)) ≈ 2.78 + 2 * ln(2999) / 2999 ≈ 2.97\n",
    "\n",
    "Therefore, the anomaly score of the data point can be computed as:\n",
    "\n",
    "score = 2 ** (-5.0 / 2.97) ≈ 0.342\n",
    "\n",
    "This score indicates that the data point is relatively likely to be an anomaly, as it has a shorter average path length than expected for an isolated point in the forest. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
